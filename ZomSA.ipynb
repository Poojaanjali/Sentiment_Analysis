{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZomSA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-4Y1ygteqZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('postivewords.txt') as pos:\n",
        "  posbag = pos.read().splitlines()\n",
        "\n",
        "with open('negativewords.txt') as neg:\n",
        "  negbag = neg.read().splitlines()\n",
        "\n",
        "with open('outfile.txt') as out:\n",
        "  bag = out.read().splitlines()\n",
        "\n",
        "import nltk\n",
        "#nltk.download('book')\n",
        "#nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import sklearn\n",
        "\n",
        "corpus = []\n",
        "for i in range(len(bag)):\n",
        "    review = re.sub('[^a-zA-Z]',' ',bag[i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    ps = WordNetLemmatizer()\n",
        "    review = [ps.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "\n",
        "\n",
        "file1=[]\n",
        "for i in range(len(corpus)):\n",
        "  wt = word_tokenize(corpus[i])\n",
        "  pos_score = 0\n",
        "  neg_score = 0\n",
        "  for w in wt:\n",
        "    if w in posbag:\n",
        "      pos_score = pos_score+1 \n",
        "    elif w in negbag:\n",
        "      neg_score = neg_score+1 \n",
        "  if pos_score > neg_score : \n",
        "    rating = 1  #Positive\n",
        "  elif pos_score < neg_score : \n",
        "    rating = -1 #Negative\n",
        "  else : \n",
        "    rating = 0 #Neutral\n",
        "  file1.append(rating)\n",
        "\n",
        "# Creating the Bag of Words model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=1500)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "y = file1\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size=0.20, random_state=0)\n",
        "\n",
        "#len(X_test) - 562\n",
        "#len(X_train) - 2248\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm1= confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Fitting classifier to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 10,\n",
        "                                    criterion = 'entropy',\n",
        "                                    random_state = 0)\n",
        "classifier.fit(X_train,y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "cm2= confusion_matrix(y_test, y_pred)\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "labels = ['neg','neutral','pos']\n",
        "ax = sns.heatmap(cm2, annot=True, fmt='d')\n",
        "ax.set_xticklabels( labels)\n",
        "ax.set_yticklabels( labels)\n",
        "\n",
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "cm3= confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#knn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, metric= 'minkowski',p=2)\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "cm4= confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm1)#91.4 accuracy\n",
        "print(cm2)#94.8\n",
        "print(cm3)#90.7\n",
        "print(cm4)#88.2\n",
        "  \n",
        "#top5 positive and negative words used in reviews\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}