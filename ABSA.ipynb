{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABSA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsZ5tH_8N_-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('ABSA16_Restaurants_Train_English_SB2.csv', sep=',', header= None)\n",
        "dataset1 = pd.read_csv('ABSA16_Restaurants_Train_SB1_v2.csv', sep=',', header= None)\n",
        "dataset.append(dataset1)\n",
        "dataset.head()\n",
        "header_row = 0\n",
        "dataset.columns = dataset.iloc[header_row]\n",
        "dataset = dataset.iloc[1:]\n",
        "dataset = dataset.rename(columns={'rid': 'id','sentences__sentence__id' :'sid','sentences__sentence__text':'review','Opinions__Opinion__category':'category','Opinions__Opinion__polarity':'polarity'})\n",
        "\n",
        "dataset['review'] = [str(i) for i in dataset['review']]\n",
        "dataset['category'] = [str(i) for i in dataset['category']]\n",
        "dataset['polarity'] = [str(i) for i in dataset['polarity']]\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "dataset.head()\n",
        "len(dataset)\n",
        "dataset.iloc[0:5,1:]\n",
        "\n",
        "dataset.category.unique()\n",
        "indexNames = dataset[ dataset['category'] == 'nan' ].index\n",
        "dataset.drop(indexNames , inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRpGXikcmNqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aspect_terms = []\n",
        "for review in nlp.pipe(dataset.review):\n",
        "    chunks = [(chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == 'NOUN']\n",
        "    aspect_terms.append(' '.join(chunks))\n",
        "dataset['aspect_terms'] = aspect_terms\n",
        "dataset.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kVM_sKhDDCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4b13342-b301-4e5b-d112-51b5abed50df"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "aspect_categories_model = Sequential()\n",
        "aspect_categories_model.add(Dense(512, input_shape=(6000,), activation='relu'))\n",
        "aspect_categories_model.add(Dense(12, activation='softmax'))\n",
        "aspect_categories_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foQNRbN6H-Lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "vocab_size = 6000 \n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(dataset['review'])\n",
        "aspect_tokenized = pd.DataFrame(tokenizer.texts_to_matrix(dataset['aspect_terms']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcxxyDBcJNG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "integer_category = label_encoder.fit_transform(dataset['category'])\n",
        "dummy_category = to_categorical(integer_category)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlYVYKnXNfQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7d4c46d4-8db7-41f1-cbf2-93b179cba6b2"
      },
      "source": [
        "aspect_categories_model.fit(aspect_tokenized, dummy_category, epochs=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1435/1435 [==============================] - 2s 2ms/step - loss: 2.3244 - accuracy: 0.2516\n",
            "Epoch 2/5\n",
            "1435/1435 [==============================] - 2s 1ms/step - loss: 2.0171 - accuracy: 0.3422\n",
            "Epoch 3/5\n",
            "1435/1435 [==============================] - 2s 1ms/step - loss: 1.8554 - accuracy: 0.4146\n",
            "Epoch 4/5\n",
            "1435/1435 [==============================] - 2s 1ms/step - loss: 1.6815 - accuracy: 0.4725\n",
            "Epoch 5/5\n",
            "1435/1435 [==============================] - 2s 1ms/step - loss: 1.5117 - accuracy: 0.5303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f70ab8d74e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fdocSQSTZPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('outfile.txt') as out:\n",
        "  bag = out.read().splitlines()\n",
        "\n",
        "for i in bag:\n",
        "  chunks = [(chunk.root.text) for chunk in nlp(i).noun_chunks if chunk.root.pos_ == 'NOUN']\n",
        "  new_review_aspect_terms = ' '.join(chunks)\n",
        "  new_review_aspect_tokenized = tokenizer.texts_to_matrix([new_review_aspect_terms])\n",
        "  new_review_category = label_encoder.inverse_transform(aspect_categories_model.predict_classes(new_review_aspect_tokenized))\n",
        "  print(new_review_category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggPjcDGKT0pS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_terms = []\n",
        "for review in nlp.pipe(dataset['review']):\n",
        "        if review.is_parsed:\n",
        "            sentiment_terms.append(' '.join([token.lemma_ for token in review if (not token.is_stop and not token.is_punct and (token.pos_ == \"ADJ\" or token.pos_ == \"VERB\"))]))\n",
        "        else:\n",
        "            sentiment_terms.append('')  \n",
        "dataset['sentiment_terms'] = sentiment_terms\n",
        "dataset.head(10)\n",
        "dataset.polarity.unique()\n",
        "indexNames = dataset[ dataset['polarity'] == 'conflict' ].index\n",
        "dataset.drop(indexNames , inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIwykKCdUCwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_model = Sequential()\n",
        "sentiment_model.add(Dense(512, input_shape=(6000,), activation='relu'))\n",
        "sentiment_model.add(Dense(3, activation='softmax'))\n",
        "sentiment_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x2XpjaQUH0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_tokenized = pd.DataFrame(tokenizer.texts_to_matrix(dataset.sentiment_terms))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsfBUS8hULxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder_2 = LabelEncoder()\n",
        "integer_sentiment = label_encoder_2.fit_transform(dataset.polarity)\n",
        "dummy_sentiment = to_categorical(integer_sentiment)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0OpXjppVRS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7da8c078-a889-47de-9180-9dac272043fa"
      },
      "source": [
        "sentiment_model.fit(sentiment_tokenized, dummy_sentiment, epochs=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1394/1394 [==============================] - 2s 1ms/step - loss: 0.8573 - accuracy: 0.7109\n",
            "Epoch 2/5\n",
            "1394/1394 [==============================] - 2s 1ms/step - loss: 0.6258 - accuracy: 0.7310\n",
            "Epoch 3/5\n",
            "1394/1394 [==============================] - 2s 1ms/step - loss: 0.5347 - accuracy: 0.7884\n",
            "Epoch 4/5\n",
            "1394/1394 [==============================] - 2s 1ms/step - loss: 0.4610 - accuracy: 0.8329\n",
            "Epoch 5/5\n",
            "1394/1394 [==============================] - 2s 1ms/step - loss: 0.4092 - accuracy: 0.8529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f70537c97b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SILYB5HaVruf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('outfile.txt') as out:\n",
        "  bag = out.read().splitlines()\n",
        "\n",
        "for i in bag:\n",
        "  chunks = [(chunk.root.text) for chunk in nlp(i).noun_chunks if chunk.root.pos_ == 'NOUN']\n",
        "  new_review_aspect_terms = ' '.join(chunks)\n",
        "  new_review_aspect_tokenized = tokenizer.texts_to_matrix([new_review_aspect_terms])\n",
        "  new_review_category = label_encoder_2.inverse_transform(sentiment_model.predict_classes(new_review_aspect_tokenized))\n",
        "  print(new_review_category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVbY8LwsV_a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('outfile.txt') as out:\n",
        "  test_reviews = out.read().splitlines()\n",
        "\n",
        "# Aspect preprocessing\n",
        "test_reviews = [review.lower() for review in test_reviews]\n",
        "test_aspect_terms = []\n",
        "for review in nlp.pipe(test_reviews):\n",
        "    chunks = [(chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == 'NOUN']\n",
        "    test_aspect_terms.append(' '.join(chunks))\n",
        "test_aspect_terms = pd.DataFrame(tokenizer.texts_to_matrix(test_aspect_terms))\n",
        "                             \n",
        "# Sentiment preprocessing\n",
        "test_sentiment_terms = []\n",
        "for review in nlp.pipe(test_reviews):\n",
        "        if review.is_parsed:\n",
        "            test_sentiment_terms.append(' '.join([token.lemma_ for token in review if (not token.is_stop and not token.is_punct and (token.pos_ == \"ADJ\" or token.pos_ == \"VERB\"))]))\n",
        "        else:\n",
        "            test_sentiment_terms.append('') \n",
        "test_sentiment_terms = pd.DataFrame(tokenizer.texts_to_matrix(test_sentiment_terms))\n",
        "\n",
        "# Models output\n",
        "test_aspect_categories = label_encoder.inverse_transform(aspect_categories_model.predict_classes(test_aspect_terms))\n",
        "test_sentiment = label_encoder_2.inverse_transform(sentiment_model.predict_classes(test_sentiment_terms))\n",
        "for i in range(61,70):\n",
        "    print(dataset.iloc[i,2] + \" is expressing a  \" + test_sentiment[i] + \" opinion about \" + test_aspect_categories[i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}